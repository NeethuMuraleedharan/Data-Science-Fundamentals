{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a862bd2d",
   "metadata": {},
   "source": [
    "Sometimes we need to install some dependant libraries. This can be run once per session, or as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12d140c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.9/site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835ef09",
   "metadata": {},
   "source": [
    "Now we can import the libraries that we will use from here on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f76e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for making the initial data table\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from extract import Extractor # loads its own dependencies\n",
    "\n",
    "# for applying the algorithm\n",
    "from extract import getTestTrain\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# for examining the performance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270eacb2",
   "metadata": {},
   "source": [
    "Once that is done, we can go ahead and merge some of the existing data tables / files in a single one that fits our requirements. This only needs to be run once initially, or as desired to change the table.\n",
    "\n",
    "Note that the warning is a false positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe67996b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    areaCode              areaName areaType        date    age  cases  \\\n",
      "0  E06000003  Redcar and Cleveland     ltla  2021-12-06  00_04      2   \n",
      "1  E06000003  Redcar and Cleveland     ltla  2021-12-06  00_59     83   \n",
      "2  E06000003  Redcar and Cleveland     ltla  2021-12-06  05_09     11   \n",
      "3  E06000003  Redcar and Cleveland     ltla  2021-12-06  10_14     15   \n",
      "4  E06000003  Redcar and Cleveland     ltla  2021-12-06  15_19      5   \n",
      "\n",
      "   rollingSum  rollingRate  VaccineRegisterPopulationByVaccinationDate  \\\n",
      "0           9        129.4                                      124077   \n",
      "1         492        509.5                                      124077   \n",
      "2          89       1073.7                                      124077   \n",
      "3          59        738.4                                      124077   \n",
      "4          38        546.6                                      124077   \n",
      "\n",
      "   cumVaccinationCompleteCoverageByVaccinationDatePercentage  \n",
      "0                                               78.6          \n",
      "1                                               78.6          \n",
      "2                                               78.6          \n",
      "3                                               78.6          \n",
      "4                                               78.6          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136/3449273910.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['neighbours'] = df.apply(lambda row: neighbours[row['areaCode']], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     areaCode              areaName areaType        date  cases    age  \\\n",
      "1   E06000003  Redcar and Cleveland     ltla  2021-12-06     83  00_59   \n",
      "13  E06000003  Redcar and Cleveland     ltla  2021-12-06      7    60+   \n",
      "23  E07000040            East Devon     ltla  2021-12-06    105  00_59   \n",
      "35  E07000040            East Devon     ltla  2021-12-06     12    60+   \n",
      "45  E07000090                Havant     ltla  2021-12-06    121  00_59   \n",
      "\n",
      "    cumVaccinationCompleteCoverageByVaccinationDatePercentage  \\\n",
      "1                                                78.6           \n",
      "13                                               78.6           \n",
      "23                                               84.3           \n",
      "35                                               84.3           \n",
      "45                                               80.8           \n",
      "\n",
      "                                           neighbours  \n",
      "1                   [E06000002, E07000164, E07000168]  \n",
      "13                  [E06000002, E07000164, E07000168]  \n",
      "23  [E06000059, E07000041, E07000042, E07000045, E...  \n",
      "35  [E06000059, E07000041, E07000042, E07000045, E...  \n",
      "45       [E06000044, E07000085, E07000094, E07000225]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136/3449273910.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Month']= df['date'].str.split('-').str[1]\n",
      "/tmp/ipykernel_136/3449273910.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Year']= df['date'].str.split('-').str[0]\n"
     ]
    }
   ],
   "source": [
    "# Begin with the root folder that all of the data will be under\n",
    "root = \"../shared_lancuni_grp_prj_2021/data\"\n",
    "\n",
    "# load the json file to use as a lookup\n",
    "neighboursPath = f\"{root}/raw/gis/gis_ltla_neighbours.json\"\n",
    "neighbours = None\n",
    "with open(neighboursPath, \"r\") as jsonIn:\n",
    "    neighbours = json.load(jsonIn)\n",
    "\n",
    "# set up the extractor\n",
    "e = Extractor(root)\n",
    "\n",
    "# merge the two tables\n",
    "casesFile = \"raw/cases_ltla_2021-12-11.csv\"\n",
    "vaccFile = \"raw/vacc_ltla_2021-12-11.csv\"\n",
    "\n",
    "# define the mapping for columns in each table which match (PK / UK)\n",
    "keys = [\n",
    "    ['areaCode', 'areaName', 'areaType', 'date'],\n",
    "    ['areaCode', 'areaName', 'areaType', 'date']\n",
    "]\n",
    "\n",
    "# load and merge the files\n",
    "e.loadFile(casesFile)\n",
    "e.importColumns(vaccFile, keys)\n",
    "\n",
    "# split date into month and year\n",
    "\n",
    "# clean up\n",
    "columns = ['areaCode',\n",
    "           'areaName',\n",
    "           'areaType',\n",
    "           'date',\n",
    "           'cases',\n",
    "           'age',\n",
    "           'cumVaccinationCompleteCoverageByVaccinationDatePercentage']\n",
    "e.filterTable(columns)\n",
    "e.deduplicate()\n",
    "\n",
    "# get our merged table out\n",
    "df = e.getTable()\n",
    "\n",
    "# remove all of the age groups (i.e. set to 00_59\n",
    "ageRanges = [\"00_59\", \"60+\"]\n",
    "df = df[df['age'].isin(ageRanges)]\n",
    "\n",
    "# add neighbour lookup\n",
    "df['neighbours'] = df.apply(lambda row: neighbours[row['areaCode']], axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# split the date into month and year - to account for seasonality\n",
    "df['Month']= df['date'].str.split('-').str[1]\n",
    "df['Year']= df['date'].str.split('-').str[0]\n",
    "\n",
    "# put it back into the extractor\n",
    "e.setTable(df)\n",
    "\n",
    "# output\n",
    "outPath = \"../data/table.csv\"\n",
    "e.saveTable(outPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51b43e",
   "metadata": {},
   "source": [
    "We have now created a table which we can use to train the decision tree.\n",
    "\n",
    "Next we will load that table, split it into test and training sets and apply the algorithm.\n",
    "\n",
    "The results will also be saved in an intermediate table so that this doesn't have to be run every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d58626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16548 rows were dropped due to empty values\n",
      "Getting the testing and training data for E06000003. 1/315\n",
      "train: (2042, 9)   predict: (686, 9)\n",
      "MSE for E06000003: 925.4897959183673\n",
      "Getting the testing and training data for E07000040. 2/315\n",
      "train: (4028, 9)   predict: (672, 9)\n",
      "MSE for E07000040: 6669.739583333333\n",
      "Getting the testing and training data for E07000090. 3/315\n",
      "train: (2690, 9)   predict: (676, 9)\n",
      "MSE for E07000090: 136.7440828402367\n",
      "Getting the testing and training data for E07000214. 4/315\n",
      "train: (4710, 9)   predict: (682, 9)\n",
      "MSE for E07000214: 202.41348973607037\n",
      "Getting the testing and training data for E07000229. 5/315\n",
      "train: (1354, 9)   predict: (672, 9)\n",
      "MSE for E07000229: 432.1815476190476\n",
      "Getting the testing and training data for E08000001. 6/315\n",
      "train: (3390, 9)   predict: (672, 9)\n",
      "MSE for E08000001: 1377.797619047619\n",
      "Getting the testing and training data for E08000009. 7/315\n",
      "train: (2704, 9)   predict: (674, 9)\n",
      "MSE for E08000009: 974.3605341246291\n",
      "Getting the testing and training data for E08000016. 8/315\n",
      "train: (4088, 9)   predict: (672, 9)\n",
      "MSE for E08000016: 766.2514880952381\n",
      "Getting the testing and training data for E08000032. 9/315\n",
      "train: (4022, 9)   predict: (672, 9)\n",
      "MSE for E08000032: 13164.912202380952\n",
      "Getting the testing and training data for E09000003. 10/315\n",
      "train: (4026, 9)   predict: (670, 9)\n",
      "MSE for E09000003: 3184.6029850746268\n",
      "Getting the testing and training data for E09000018. 11/315\n",
      "train: (3346, 9)   predict: (670, 9)\n",
      "MSE for E09000018: 1496.431343283582\n",
      "Getting the testing and training data for E09000032. 12/315\n",
      "train: (2712, 9)   predict: (684, 9)\n",
      "MSE for E09000032: 1662.0116959064328\n",
      "Getting the testing and training data for E09000033. 13/315\n",
      "train: (2010, 9)   predict: (670, 9)\n",
      "MSE for E09000033: 385.87014925373137\n",
      "Getting the testing and training data for E07000006. 14/315\n",
      "train: (4042, 9)   predict: (682, 9)\n",
      "MSE for E07000006: 942.8856304985337\n",
      "Getting the testing and training data for E07000067. 15/315\n",
      "train: (4752, 9)   predict: (680, 9)\n",
      "MSE for E07000067: 522.3558823529412\n",
      "Getting the testing and training data for E07000094. 16/315\n",
      "train: (4716, 9)   predict: (672, 9)\n",
      "MSE for E07000094: 203.60416666666666\n",
      "Getting the testing and training data for E07000125. 17/315\n",
      "train: (4038, 9)   predict: (670, 9)\n",
      "MSE for E07000125: 1341.3179104477613\n",
      "Getting the testing and training data for E07000155. 18/315\n",
      "train: (4784, 9)   predict: (682, 9)\n",
      "MSE for E07000155: 1439.3782991202347\n",
      "Getting the testing and training data for E07000169. 19/315\n",
      "train: (4036, 9)   predict: (668, 9)\n",
      "MSE for E07000169: 4534.577844311377\n",
      "Getting the testing and training data for E07000187. 20/315\n",
      "train: (3362, 9)   predict: (672, 9)\n",
      "MSE for E07000187: 390.70386904761904\n",
      "Getting the testing and training data for E07000203. 21/315\n",
      "train: (4032, 9)   predict: (670, 9)\n",
      "MSE for E07000203: 74.59850746268657\n",
      "Getting the testing and training data for E07000234. 22/315\n",
      "train: (5356, 9)   predict: (672, 9)\n",
      "MSE for E07000234: 197.4985119047619\n",
      "Getting the testing and training data for E08000037. 23/315\n",
      "train: (2688, 9)   predict: (672, 9)\n",
      "MSE for E08000037: 1025.0982142857142\n",
      "Getting the testing and training data for E09000024. 24/315\n",
      "train: (3404, 9)   predict: (684, 9)\n",
      "MSE for E09000024: 1355.2280701754387\n",
      "Getting the testing and training data for E06000038. 25/315\n",
      "train: (2072, 9)   predict: (672, 9)\n",
      "MSE for E06000038: 812.0074404761905\n",
      "Getting the testing and training data for E07000010. 26/315\n",
      "train: (3334, 9)   predict: (670, 9)\n",
      "MSE for E07000010: 102.73134328358209\n",
      "Getting the testing and training data for E07000031. 27/315\n",
      "train: (4612, 9)   predict: (666, 9)\n",
      "MSE for E07000031: 135.13513513513513\n",
      "Getting the testing and training data for E07000079. 28/315\n",
      "train: (6854, 9)   predict: (678, 9)\n",
      "MSE for E07000079: 2643.660766961652\n",
      "Getting the testing and training data for E07000096. 29/315\n",
      "train: (3360, 9)   predict: (668, 9)\n",
      "MSE for E07000096: 271.0748502994012\n",
      "Getting the testing and training data for E07000099. 30/315\n",
      "train: (5408, 9)   predict: (678, 9)\n",
      "MSE for E07000099: 273.9646017699115\n",
      "Getting the testing and training data for E07000145. 31/315\n",
      "train: (2016, 9)   predict: (674, 9)\n",
      "MSE for E07000145: 771.1409495548961\n",
      "Getting the testing and training data for E07000189. 32/315\n",
      "train: (4030, 9)   predict: (674, 9)\n",
      "MSE for E07000189: 244.93768545994067\n",
      "Getting the testing and training data for E07000235. 33/315\n",
      "train: (4692, 9)   predict: (672, 9)\n",
      "MSE for E07000235: 5333.836309523809\n",
      "Getting the testing and training data for E08000015. 34/315\n",
      "train: (686, 9)   predict: (686, 9)\n",
      "MSE for E08000015: 1734.9212827988338\n",
      "Getting the testing and training data for E08000021. 35/315\n",
      "train: (1346, 9)   predict: (674, 9)\n",
      "MSE for E08000021: 1288.1038575667656\n",
      "Getting the testing and training data for E06000004. 36/315\n",
      "train: (3410, 9)   predict: (686, 9)\n",
      "MSE for E06000004: 968.265306122449\n",
      "Getting the testing and training data for E06000021. 37/315\n",
      "train: (2048, 9)   predict: (684, 9)\n",
      "MSE for E06000021: 2174.6681286549706\n",
      "Getting the testing and training data for E06000030. 38/315\n",
      "train: (2078, 9)   predict: (678, 9)\n",
      "MSE for E06000030: 2633.9218289085547\n",
      "Getting the testing and training data for E07000026. 39/315\n",
      "train: (2680, 9)   predict: (674, 9)\n",
      "MSE for E07000026: 318.89762611275967\n",
      "Getting the testing and training data for E07000032. 40/315\n",
      "train: (5416, 9)   predict: (674, 9)\n",
      "MSE for E07000032: 503.3649851632047\n",
      "Getting the testing and training data for E07000069. 41/315\n",
      "train: (2026, 9)   predict: (678, 9)\n",
      "MSE for E07000069: 159.52654867256638\n",
      "Getting the testing and training data for E07000119. 42/315\n",
      "train: (2058, 9)   predict: (686, 9)\n",
      "MSE for E07000119: 594.6836734693877\n",
      "Getting the testing and training data for E07000140. 43/315\n",
      "train: (4044, 9)   predict: (650, 9)\n",
      "MSE for E07000140: 103.71076923076923\n",
      "Getting the testing and training data for E07000168. 44/315\n",
      "train: (2724, 9)   predict: (672, 9)\n",
      "MSE for E07000168: 302.29315476190476\n",
      "Getting the testing and training data for E07000212. 45/315\n",
      "train: (3364, 9)   predict: (670, 9)\n",
      "MSE for E07000212: 122.65223880597014\n",
      "Getting the testing and training data for E08000011. 46/315\n",
      "train: (3392, 9)   predict: (678, 9)\n",
      "MSE for E08000011: 2756.7625368731565\n",
      "Getting the testing and training data for E09000020. 47/315\n",
      "train: (2010, 9)   predict: (668, 9)\n",
      "MSE for E09000020: 374.45359281437123\n",
      "Getting the testing and training data for E09000026. 48/315\n",
      "train: (3348, 9)   predict: (670, 9)\n",
      "MSE for E09000026: 1415.4582089552239\n",
      "Getting the testing and training data for E06000005. 49/315\n",
      "train: (2712, 9)   predict: (686, 9)\n",
      "MSE for E06000005: 1178.2128279883382\n",
      "Getting the testing and training data for E06000051. 50/315\n",
      "train: (6080, 9)   predict: (682, 9)\n",
      "MSE for E06000051: 5688.409090909091\n",
      "Getting the testing and training data for E07000072. 51/315\n",
      "train: (6738, 9)   predict: (672, 9)\n",
      "MSE for E07000072: 385.3511904761905\n",
      "Getting the testing and training data for E07000074. 52/315\n",
      "train: (2046, 9)   predict: (684, 9)\n",
      "MSE for E07000074: 916.9093567251462\n",
      "Getting the testing and training data for E07000088. 53/315\n",
      "train: (678, 9)   predict: (678, 9)\n",
      "MSE for E07000088: 125.68879056047197\n",
      "Getting the testing and training data for E07000095. 54/315\n",
      "train: (2692, 9)   predict: (672, 9)\n",
      "MSE for E07000095: 162.38690476190476\n",
      "Getting the testing and training data for E07000154. 55/315\n",
      "train: (2042, 9)   predict: (684, 9)\n",
      "MSE for E07000154: 2810.004385964912\n",
      "Getting the testing and training data for E07000221. 56/315\n",
      "train: (7522, 9)   predict: (670, 9)\n",
      "MSE for E07000221: 190.89850746268658\n",
      "Getting the testing and training data for E07000238. 57/315\n",
      "train: (5352, 9)   predict: (668, 9)\n",
      "MSE for E07000238: 244.1437125748503\n",
      "Getting the testing and training data for E07000239. 58/315\n",
      "train: (3366, 9)   predict: (664, 9)\n",
      "MSE for E07000239: 125.18373493975903\n",
      "Getting the testing and training data for E07000240. 59/315\n",
      "train: (4708, 9)   predict: (672, 9)\n",
      "MSE for E07000240: 246.64136904761904\n",
      "Getting the testing and training data for E09000016. 60/315\n",
      "train: (3370, 9)   predict: (670, 9)\n",
      "MSE for E09000016: 655.1044776119403\n",
      "Getting the testing and training data for E09000019. 61/315\n",
      "train: (2014, 9)   predict: (672, 9)\n",
      "MSE for E09000019: 215.60714285714286\n",
      "Getting the testing and training data for E06000054. 62/315\n",
      "train: (7520, 9)   predict: (672, 9)\n",
      "MSE for E06000054: 13881.483630952382\n",
      "Getting the testing and training data for E07000012. 63/315\n",
      "train: (5402, 9)   predict: (684, 9)\n",
      "MSE for E07000012: 186.4795321637427\n",
      "Getting the testing and training data for E07000034. 64/315\n",
      "train: (1348, 9)   predict: (674, 9)\n",
      "MSE for E07000034: 138.7967359050445\n",
      "Getting the testing and training data for E07000035. 65/315\n",
      "train: (4790, 9)   predict: (682, 9)\n",
      "MSE for E07000035: 507.5674486803519\n",
      "Getting the testing and training data for E07000080. 66/315\n",
      "train: (2018, 9)   predict: (676, 9)\n",
      "MSE for E07000080: 158.64940828402368\n",
      "Getting the testing and training data for E07000110. 67/315\n",
      "train: (3352, 9)   predict: (672, 9)\n",
      "MSE for E07000110: 260.9434523809524\n",
      "Getting the testing and training data for E07000130. 68/315\n",
      "train: (4728, 9)   predict: (674, 9)\n",
      "MSE for E07000130: 912.1928783382789\n",
      "Getting the testing and training data for E07000146. 69/315\n",
      "train: (4008, 9)   predict: (672, 9)\n",
      "MSE for E07000146: 178.40029761904762\n",
      "Getting the testing and training data for E07000171. 70/315\n",
      "train: (4716, 9)   predict: (668, 9)\n",
      "MSE for E07000171: 623.1032934131737\n",
      "Getting the testing and training data for E07000198. 71/315\n",
      "train: (4756, 9)   predict: (684, 9)\n",
      "MSE for E07000198: 3561.2587719298244\n",
      "Getting the testing and training data for E08000030. 72/315\n",
      "train: (4036, 9)   predict: (674, 9)\n",
      "MSE for E08000030: 2823.9480712166173\n",
      "Getting the testing and training data for E09000007. 73/315\n",
      "train: (3354, 9)   predict: (672, 9)\n",
      "MSE for E09000007: 4593.145833333333\n",
      "Getting the testing and training data for E09000013. 74/315\n",
      "train: (2676, 9)   predict: (670, 9)\n",
      "MSE for E09000013: 1248.7731343283583\n",
      "Getting the testing and training data for E06000013. 75/315\n",
      "train: (3376, 9)   predict: (672, 9)\n",
      "MSE for E06000013: 353.4375\n",
      "Getting the testing and training data for E06000025. 76/315\n",
      "train: (3424, 9)   predict: (676, 9)\n",
      "MSE for E06000025: 5403.653846153846\n",
      "Getting the testing and training data for E06000026. 77/315\n",
      "train: (678, 9)   predict: (678, 9)\n",
      "MSE for E06000026: 4195.399705014749\n",
      "Getting the testing and training data for E06000040. 78/315\n",
      "train: (5406, 9)   predict: (674, 9)\n",
      "MSE for E06000040: 494.89614243323444\n",
      "Getting the testing and training data for E06000059. 79/315\n",
      "train: (3418, 9)   predict: (672, 9)\n",
      "MSE for E06000059: 3496.815476190476\n",
      "Getting the testing and training data for E07000027. 80/315\n",
      "train: (666, 9)   predict: (570, 9)\n",
      "MSE for E07000027: 123.60701754385966\n",
      "Getting the testing and training data for E07000063. 81/315\n",
      "train: (2034, 9)   predict: (684, 9)\n",
      "MSE for E07000063: 4149.008771929824\n",
      "Getting the testing and training data for E07000077. 82/315\n",
      "train: (4074, 9)   predict: (674, 9)\n",
      "MSE for E07000077: 508.52225519287833\n",
      "Getting the testing and training data for E07000086. 83/315\n",
      "train: (2016, 9)   predict: (672, 9)\n",
      "MSE for E07000086: 245.33482142857142\n",
      "Getting the testing and training data for E07000122. 84/315\n",
      "train: (3368, 9)   predict: (670, 9)\n",
      "MSE for E07000122: 14845.928358208956\n",
      "Getting the testing and training data for E07000200. 85/315\n",
      "train: (4058, 9)   predict: (672, 9)\n",
      "MSE for E07000200: 319.01636904761904\n",
      "Getting the testing and training data for E08000027. 86/315\n",
      "train: (3360, 9)   predict: (672, 9)\n",
      "MSE for E08000027: 3486.3318452380954\n",
      "Getting the testing and training data for E08000029. 87/315\n",
      "train: (4028, 9)   predict: (674, 9)\n",
      "MSE for E08000029: 1816.479228486647\n",
      "Getting the testing and training data for E06000019. 88/315\n",
      "train: (2030, 9)   predict: (670, 9)\n",
      "MSE for E06000019: 1607.1955223880598\n",
      "Getting the testing and training data for E06000049. 89/315\n",
      "train: (6152, 9)   predict: (678, 9)\n",
      "MSE for E06000049: 1605.2861356932153\n",
      "Getting the testing and training data for E07000039. 90/315\n",
      "train: (4734, 9)   predict: (682, 9)\n",
      "MSE for E07000039: 163.95307917888562\n",
      "Getting the testing and training data for E07000076. 91/315\n",
      "train: (1354, 9)   predict: (682, 9)\n",
      "MSE for E07000076: 700.241935483871\n",
      "Getting the testing and training data for E07000102. 92/315\n",
      "train: (5376, 9)   predict: (674, 9)\n",
      "MSE for E07000102: 121.24183976261128\n",
      "Getting the testing and training data for E07000135. 93/315\n",
      "train: (2024, 9)   predict: (676, 9)\n",
      "MSE for E07000135: 820.2455621301775\n",
      "Getting the testing and training data for E07000167. 94/315\n",
      "train: (2710, 9)   predict: (672, 9)\n",
      "MSE for E07000167: 336.9002976190476\n",
      "Getting the testing and training data for E07000180. 95/315\n",
      "train: (5612, 9)   predict: (728, 9)\n",
      "MSE for E07000180: 331.6043956043956\n",
      "Getting the testing and training data for E08000018. 96/315\n",
      "train: (4088, 9)   predict: (672, 9)\n",
      "MSE for E08000018: 1191.28125\n",
      "Getting the testing and training data for E08000026. 97/315\n",
      "train: (3364, 9)   predict: (672, 9)\n",
      "MSE for E08000026: 1919.9806547619048\n",
      "Getting the testing and training data for E08000034. 98/315\n",
      "train: (4706, 9)   predict: (670, 9)\n",
      "MSE for E08000034: 2239.1194029850744\n",
      "Getting the testing and training data for E09000030. 99/315\n",
      "train: (1334, 9)   predict: (670, 9)\n",
      "MSE for E09000030: 660.755223880597\n",
      "Getting the testing and training data for E06000008. 100/315\n",
      "train: (4744, 9)   predict: (670, 9)\n",
      "MSE for E06000008: 1853.7537313432836\n",
      "Getting the testing and training data for E06000039. 101/315\n",
      "train: (2692, 9)   predict: (684, 9)\n",
      "MSE for E06000039: 1248.8479532163742\n",
      "Getting the testing and training data for E07000008. 102/315\n",
      "train: (684, 9)   predict: (684, 9)\n",
      "MSE for E07000008: 388.2426900584795\n",
      "Getting the testing and training data for E07000030. 103/315\n",
      "train: (4028, 9)   predict: (668, 9)\n",
      "MSE for E07000030: 356.8293413173653\n",
      "Getting the testing and training data for E07000137. 104/315\n",
      "train: (2714, 9)   predict: (672, 9)\n",
      "MSE for E07000137: 172.72619047619048\n",
      "Getting the testing and training data for E07000142. 105/315\n",
      "train: (4722, 9)   predict: (684, 9)\n",
      "MSE for E07000142: 278.5687134502924\n",
      "Getting the testing and training data for E07000199. 106/315\n",
      "train: (1344, 9)   predict: (668, 9)\n",
      "MSE for E07000199: 183.7005988023952\n",
      "Getting the testing and training data for E07000224. 107/315\n",
      "train: (2696, 9)   predict: (672, 9)\n",
      "MSE for E07000224: 454.3363095238095\n",
      "Getting the testing and training data for E07000246. 108/315\n",
      "train: (3322, 9)   predict: (670, 9)\n",
      "MSE for E07000246: 704.9910447761195\n",
      "Getting the testing and training data for E08000014. 109/315\n",
      "train: (2044, 9)   predict: (684, 9)\n",
      "MSE for E08000014: 2217.5219298245615\n",
      "Getting the testing and training data for E09000002. 110/315\n",
      "train: (2004, 9)   predict: (672, 9)\n",
      "MSE for E09000002: 909.25\n",
      "Getting the testing and training data for E09000005. 111/315\n",
      "train: (4690, 9)   predict: (670, 9)\n",
      "MSE for E09000005: 1269.0611940298506\n",
      "Getting the testing and training data for E09000011. 112/315\n",
      "train: (2014, 9)   predict: (672, 9)\n",
      "MSE for E09000011: 312.9717261904762\n",
      "Getting the testing and training data for E06000046. 113/315\n",
      "train: (0, 9)   predict: (672, 9)\n",
      "Missing data. Skipping E06000046\n",
      "Getting the testing and training data for E06000052. 114/315\n",
      "train: (1350, 9)   predict: (684, 9)\n",
      "MSE for E06000052: 20859.793859649122\n",
      "Getting the testing and training data for E07000042. 115/315\n",
      "train: (4000, 9)   predict: (668, 9)\n",
      "MSE for E07000042: 354.77245508982037\n",
      "Getting the testing and training data for E07000085. 116/315\n",
      "train: (4032, 9)   predict: (672, 9)\n",
      "MSE for E07000085: 196.45684523809524\n",
      "Getting the testing and training data for E07000093. 117/315\n",
      "train: (4758, 9)   predict: (672, 9)\n",
      "MSE for E07000093: 408.9717261904762\n",
      "Getting the testing and training data for E07000108. 118/315\n",
      "train: (2014, 9)   predict: (670, 9)\n",
      "MSE for E07000108: 219.74477611940299\n",
      "Getting the testing and training data for E07000111. 119/315\n",
      "train: (5366, 9)   predict: (670, 9)\n",
      "MSE for E07000111: 189.82388059701492\n",
      "Getting the testing and training data for E07000114. 120/315\n",
      "train: (1342, 9)   predict: (672, 9)\n",
      "MSE for E07000114: 150.5907738095238\n",
      "Getting the testing and training data for E07000124. 121/315\n",
      "train: (6096, 9)   predict: (680, 9)\n",
      "MSE for E07000124: 139.33970588235294\n",
      "Getting the testing and training data for E07000193. 122/315\n",
      "train: (3404, 9)   predict: (674, 9)\n",
      "MSE for E07000193: 454.61127596439167\n",
      "Getting the testing and training data for E07000211. 123/315\n",
      "train: (4052, 9)   predict: (670, 9)\n",
      "MSE for E07000211: 726.2089552238806\n",
      "Getting the testing and training data for E07000220. 124/315\n",
      "train: (5396, 9)   predict: (674, 9)\n",
      "MSE for E07000220: 682.0192878338279\n",
      "Getting the testing and training data for E07000236. 125/315\n",
      "train: (2010, 9)   predict: (664, 9)\n",
      "MSE for E07000236: 121.90210843373494\n",
      "Getting the testing and training data for E08000022. 126/315\n",
      "train: (1348, 9)   predict: (672, 9)\n",
      "MSE for E08000022: 758.5431547619048\n",
      "Getting the testing and training data for E08000024. 127/315\n",
      "train: (2014, 9)   predict: (672, 9)\n",
      "MSE for E08000024: 1044.0505952380952\n",
      "Getting the testing and training data for E06000009. 128/315\n",
      "train: (1372, 9)   predict: (686, 9)\n",
      "MSE for E06000009: 746.204081632653\n",
      "Getting the testing and training data for E06000022. 129/315\n",
      "train: (3422, 9)   predict: (670, 9)\n",
      "MSE for E06000022: 1842.3731343283582\n",
      "Getting the testing and training data for E06000055. 130/315\n",
      "train: (3370, 9)   predict: (656, 9)\n",
      "MSE for E06000055: 415.9710365853659\n",
      "Getting the testing and training data for E07000033. 131/315\n",
      "train: (4708, 9)   predict: (674, 9)\n",
      "MSE for E07000033: 329.52225519287833\n",
      "Getting the testing and training data for E07000038. 132/315\n",
      "train: (4104, 9)   predict: (674, 9)\n",
      "MSE for E07000038: 305.0682492581602\n",
      "Getting the testing and training data for E07000064. 133/315\n",
      "train: (3338, 9)   predict: (664, 9)\n",
      "MSE for E07000064: 505.0421686746988\n",
      "Getting the testing and training data for E07000123. 134/315\n",
      "train: (2736, 9)   predict: (686, 9)\n",
      "MSE for E07000123: 564.704081632653\n",
      "Getting the testing and training data for E07000197. 135/315\n",
      "train: (6100, 9)   predict: (682, 9)\n",
      "MSE for E07000197: 2041.0146627565982\n",
      "Getting the testing and training data for E07000207. 136/315\n",
      "train: (4700, 9)   predict: (670, 9)\n",
      "MSE for E07000207: 526.5850746268657\n",
      "Getting the testing and training data for E08000012. 137/315\n",
      "train: (2034, 9)   predict: (684, 9)\n",
      "MSE for E08000012: 9648.0\n",
      "Getting the testing and training data for E09000028. 138/315\n",
      "train: (2020, 9)   predict: (674, 9)\n",
      "MSE for E09000028: 366.25964391691394\n",
      "Getting the testing and training data for E09000031. 139/315\n",
      "train: (4018, 9)   predict: (670, 9)\n",
      "MSE for E09000031: 322.0865671641791\n",
      "Getting the testing and training data for E06000043. 140/315\n",
      "train: (2716, 9)   predict: (684, 9)\n",
      "MSE for E06000043: 4141.464912280701\n",
      "Getting the testing and training data for E06000057. 141/315\n",
      "train: (4030, 9)   predict: (674, 9)\n",
      "MSE for E06000057: 4811.182492581603\n",
      "Getting the testing and training data for E07000011. 142/315\n",
      "train: (4702, 9)   predict: (670, 9)\n",
      "MSE for E07000011: 803.3820895522388\n",
      "Getting the testing and training data for E07000089. 143/315\n",
      "train: (4720, 9)   predict: (672, 9)\n",
      "MSE for E07000089: 184.29464285714286\n",
      "Getting the testing and training data for E07000120. 144/315\n",
      "train: (2692, 9)   predict: (672, 9)\n",
      "MSE for E07000120: 204.55059523809524\n",
      "Getting the testing and training data for E07000141. 145/315\n",
      "train: (4696, 9)   predict: (672, 9)\n",
      "MSE for E07000141: 238.0952380952381\n",
      "Getting the testing and training data for E07000178. 146/315\n",
      "train: (2184, 9)   predict: (728, 9)\n",
      "MSE for E07000178: 438.0315934065934\n",
      "Getting the testing and training data for E07000209. 147/315\n",
      "train: (4038, 9)   predict: (672, 9)\n",
      "MSE for E07000209: 189.62053571428572\n",
      "Getting the testing and training data for E09000010. 148/315\n",
      "train: (4700, 9)   predict: (670, 9)\n",
      "MSE for E09000010: 2383.1776119402984\n",
      "Getting the testing and training data for E06000002. 149/315\n",
      "train: (2056, 9)   predict: (686, 9)\n",
      "MSE for E06000002: 342.1093294460641\n",
      "Getting the testing and training data for E06000020. 150/315\n",
      "train: (2036, 9)   predict: (674, 9)\n",
      "MSE for E06000020: 2179.455489614243\n",
      "Getting the testing and training data for E07000004. 151/315\n",
      "train: (5492, 9)   predict: (670, 9)\n",
      "MSE for E07000004: 552.9149253731343\n",
      "Getting the testing and training data for E07000036. 152/315\n",
      "train: (4070, 9)   predict: (674, 9)\n",
      "MSE for E07000036: 165.16617210682492\n",
      "Getting the testing and training data for E07000121. 153/315\n",
      "train: (2704, 9)   predict: (684, 9)\n",
      "MSE for E07000121: 499.6432748538012\n",
      "Getting the testing and training data for E07000131. 154/315\n",
      "train: (6798, 9)   predict: (676, 9)\n",
      "MSE for E07000131: 632.1183431952662\n",
      "Getting the testing and training data for E07000219. 155/315\n",
      "train: (2690, 9)   predict: (674, 9)\n",
      "MSE for E07000219: 6033.918397626113\n",
      "Getting the testing and training data for E07000244. 156/315\n",
      "train: (2688, 9)   predict: (672, 9)\n",
      "MSE for E07000244: 941.0282738095239\n",
      "Getting the testing and training data for E07000245. 157/315\n",
      "train: (4722, 9)   predict: (672, 9)\n",
      "MSE for E07000245: 264.8675595238095\n",
      "Getting the testing and training data for E08000004. 158/315\n",
      "train: (4030, 9)   predict: (672, 9)\n",
      "MSE for E08000004: 4432.263392857143\n",
      "Getting the testing and training data for E09000021. 159/315\n",
      "train: (4736, 9)   predict: (678, 9)\n",
      "MSE for E09000021: 3394.7227138643066\n",
      "Getting the testing and training data for E09000025. 160/315\n",
      "train: (3352, 9)   predict: (664, 9)\n",
      "MSE for E09000025: 803.0451807228916\n",
      "Getting the testing and training data for E06000011. 161/315\n",
      "train: (4702, 9)   predict: (682, 9)\n",
      "MSE for E06000011: 4554.7111436950145\n",
      "Getting the testing and training data for E06000036. 162/315\n",
      "train: (2700, 9)   predict: (678, 9)\n",
      "MSE for E06000036: 231.82890855457228\n",
      "Getting the testing and training data for E06000041. 163/315\n",
      "train: (5436, 9)   predict: (672, 9)\n",
      "MSE for E06000041: 409.33035714285717\n",
      "Getting the testing and training data for E06000042. 164/315\n",
      "train: (3358, 9)   predict: (672, 9)\n",
      "MSE for E06000042: 2928.1071428571427\n",
      "Getting the testing and training data for E07000087. 165/315\n",
      "train: (2026, 9)   predict: (678, 9)\n",
      "MSE for E07000087: 207.5796460176991\n",
      "Getting the testing and training data for E07000103. 166/315\n",
      "train: (2016, 9)   predict: (672, 9)\n",
      "MSE for E07000103: 565.0610119047619\n",
      "Getting the testing and training data for E07000136. 167/315\n",
      "train: (2006, 9)   predict: (676, 9)\n",
      "MSE for E07000136: 85.01923076923077\n",
      "Getting the testing and training data for E07000152. 168/315\n",
      "train: (5418, 9)   predict: (678, 9)\n",
      "MSE for E07000152: 966.8702064896755\n",
      "Getting the testing and training data for E07000202. 169/315\n",
      "train: (2014, 9)   predict: (672, 9)\n",
      "MSE for E07000202: 462.66815476190476\n",
      "Getting the testing and training data for E07000213. 170/315\n",
      "train: (4708, 9)   predict: (668, 9)\n",
      "MSE for E07000213: 3280.145209580838\n",
      "Getting the testing and training data for E07000223. 171/315\n",
      "train: (2700, 9)   predict: (682, 9)\n",
      "MSE for E07000223: 441.88269794721407\n",
      "Getting the testing and training data for E06000014. 172/315\n",
      "train: (3372, 9)   predict: (672, 9)\n",
      "MSE for E06000014: 1529.532738095238\n",
      "Getting the testing and training data for E07000028. 173/315\n",
      "train: (2016, 9)   predict: (672, 9)\n",
      "MSE for E07000028: 468.48214285714283\n",
      "Getting the testing and training data for E07000029. 174/315\n",
      "train: (1340, 9)   predict: (674, 9)\n",
      "MSE for E07000029: 165.79525222551928\n",
      "Getting the testing and training data for E07000062. 175/315\n",
      "train: (664, 9)   predict: (652, 9)\n",
      "MSE for E07000062: 140.59969325153375\n",
      "Getting the testing and training data for E07000065. 176/315\n",
      "train: (4710, 9)   predict: (672, 9)\n",
      "MSE for E07000065: 429.6309523809524\n",
      "Getting the testing and training data for E07000075. 177/315\n",
      "train: (2714, 9)   predict: (674, 9)\n",
      "MSE for E07000075: 148.25370919881306\n",
      "Getting the testing and training data for E07000113. 178/315\n",
      "train: (2686, 9)   predict: (672, 9)\n",
      "MSE for E07000113: 305.1220238095238\n",
      "Getting the testing and training data for E07000156. 179/315\n",
      "train: (4728, 9)   predict: (678, 9)\n",
      "MSE for E07000156: 163.65486725663717\n",
      "Getting the testing and training data for E07000166. 180/315\n",
      "train: (4714, 9)   predict: (670, 9)\n",
      "MSE for E07000166: 400.7835820895522\n",
      "Getting the testing and training data for E07000188. 181/315\n",
      "train: (2690, 9)   predict: (672, 9)\n",
      "MSE for E07000188: 466.8363095238095\n",
      "Getting the testing and training data for E07000210. 182/315\n",
      "train: (5380, 9)   predict: (670, 9)\n",
      "MSE for E07000210: 875.3507462686567\n",
      "Getting the testing and training data for E07000237. 183/315\n",
      "train: (1340, 9)   predict: (656, 9)\n",
      "MSE for E07000237: 344.1600609756098\n",
      "Getting the testing and training data for E08000035. 184/315\n",
      "train: (3348, 9)   predict: (672, 9)\n",
      "MSE for E08000035: 17252.650297619046\n",
      "Getting the testing and training data for E06000023. 185/315\n",
      "train: (2020, 9)   predict: (728, 9)\n",
      "MSE for E06000023: 4622.721153846154\n",
      "Getting the testing and training data for E06000050. 186/315\n",
      "train: (3390, 9)   predict: (686, 9)\n",
      "MSE for E06000050: 1607.871720116618\n",
      "Getting the testing and training data for E07000061. 187/315\n",
      "train: (672, 9)   predict: (670, 9)\n",
      "MSE for E07000061: 304.0776119402985\n",
      "Getting the testing and training data for E07000070. 188/315\n",
      "train: (4746, 9)   predict: (684, 9)\n",
      "MSE for E07000070: 568.8508771929825\n",
      "Getting the testing and training data for E07000118. 189/315\n",
      "train: (3378, 9)   predict: (684, 9)\n",
      "MSE for E07000118: 3695.2719298245615\n",
      "Getting the testing and training data for E07000139. 190/315\n",
      "train: (4710, 9)   predict: (684, 9)\n",
      "MSE for E07000139: 137.48976608187135\n",
      "Getting the testing and training data for E07000179. 191/315\n",
      "train: (5540, 9)   predict: (728, 9)\n",
      "MSE for E07000179: 443.7541208791209\n",
      "Getting the testing and training data for E07000181. 192/315\n",
      "train: (2804, 9)   predict: (728, 9)\n",
      "MSE for E07000181: 139.8901098901099\n",
      "Getting the testing and training data for E07000196. 193/315\n",
      "train: (6066, 9)   predict: (672, 9)\n",
      "MSE for E07000196: 329.5327380952381\n",
      "Getting the testing and training data for E08000007. 194/315\n",
      "train: (2696, 9)   predict: (728, 9)\n",
      "MSE for E08000007: 2127.0837912087914\n",
      "Getting the testing and training data for E08000023. 195/315\n",
      "train: (1344, 9)   predict: (670, 9)\n",
      "MSE for E08000023: 614.3358208955224\n",
      "Getting the testing and training data for E08000031. 196/315\n",
      "train: (2690, 9)   predict: (672, 9)\n",
      "MSE for E08000031: 423.70684523809524\n",
      "Getting the testing and training data for E09000014. 197/315\n",
      "train: (4024, 9)   predict: (672, 9)\n",
      "MSE for E09000014: 2837.1934523809523\n",
      "Getting the testing and training data for E06000015. 198/315\n",
      "train: (2030, 9)   predict: (682, 9)\n",
      "MSE for E06000015: 1965.7390029325513\n",
      "Getting the testing and training data for E07000005. 199/315\n",
      "train: (3364, 9)   predict: (672, 9)\n",
      "MSE for E07000005: 208.38541666666666\n",
      "Getting the testing and training data for E07000046. 200/315\n",
      "train: (2670, 9)   predict: (668, 9)\n",
      "MSE for E07000046: 25513.672155688622\n",
      "Getting the testing and training data for E07000081. 201/315\n",
      "train: (1352, 9)   predict: (682, 9)\n",
      "MSE for E07000081: 352.9120234604106\n",
      "Getting the testing and training data for E07000098. 202/315\n",
      "train: (4704, 9)   predict: (670, 9)\n",
      "MSE for E07000098: 6218.858208955224\n",
      "Getting the testing and training data for E07000143. 203/315\n",
      "train: (4030, 9)   predict: (672, 9)\n",
      "MSE for E07000143: 203.6577380952381\n",
      "Getting the testing and training data for E07000144. 204/315\n",
      "train: (3362, 9)   predict: (672, 9)\n",
      "MSE for E07000144: 203.67708333333334\n",
      "Getting the testing and training data for E07000150. 205/315\n",
      "train: (2700, 9)   predict: (726, 9)\n",
      "MSE for E07000150: 224.2479338842975\n",
      "Getting the testing and training data for E07000172. 206/315\n",
      "train: (3370, 9)   predict: (674, 9)\n",
      "MSE for E07000172: 204.01632047477744\n",
      "Getting the testing and training data for E07000174. 207/315\n",
      "train: (2686, 9)   predict: (672, 9)\n",
      "MSE for E07000174: 268.125\n",
      "Getting the testing and training data for E08000002. 208/315\n",
      "train: (4036, 9)   predict: (682, 9)\n",
      "MSE for E08000002: 1293.4956011730205\n",
      "Getting the testing and training data for E09000027. 209/315\n",
      "train: (3370, 9)   predict: (672, 9)\n",
      "MSE for E09000027: 5201.273809523809\n",
      "Getting the testing and training data for E06000016. 210/315\n",
      "train: (2702, 9)   predict: (672, 9)\n",
      "MSE for E06000016: 3671.434523809524\n",
      "Getting the testing and training data for E06000024. 211/315\n",
      "train: (2742, 9)   predict: (674, 9)\n",
      "MSE for E06000024: 1398.320474777448\n",
      "Getting the testing and training data for E06000027. 212/315\n",
      "train: (1350, 9)   predict: (670, 9)\n",
      "MSE for E06000027: 537.0149253731344\n",
      "Getting the testing and training data for E06000058. 213/315\n",
      "train: (1400, 9)   predict: (672, 9)\n",
      "MSE for E06000058: 4049.8065476190477\n",
      "Getting the testing and training data for E07000037. 214/315\n",
      "train: (6188, 9)   predict: (674, 9)\n",
      "MSE for E07000037: 3058.3293768545996\n",
      "Getting the testing and training data for E07000106. 215/315\n",
      "train: (3356, 9)   predict: (672, 9)\n",
      "MSE for E07000106: 221.81994047619048\n",
      "Getting the testing and training data for E07000107. 216/315\n",
      "train: (2012, 9)   predict: (670, 9)\n",
      "MSE for E07000107: 384.7985074626866\n",
      "Getting the testing and training data for E07000133. 217/315\n",
      "train: (4048, 9)   predict: (672, 9)\n",
      "MSE for E07000133: 1024.1815476190477\n",
      "Getting the testing and training data for E07000163. 218/315\n",
      "train: (4708, 9)   predict: (672, 9)\n",
      "MSE for E07000163: 18381.636904761905\n",
      "Getting the testing and training data for E07000216. 219/315\n",
      "train: (4702, 9)   predict: (672, 9)\n",
      "MSE for E07000216: 190.96279761904762\n",
      "Getting the testing and training data for E07000241. 220/315\n",
      "train: (4038, 9)   predict: (674, 9)\n",
      "MSE for E07000241: 198.17507418397625\n",
      "Getting the testing and training data for E08000017. 221/315\n",
      "train: (4706, 9)   predict: (672, 9)\n",
      "MSE for E08000017: 661.6220238095239\n",
      "Getting the testing and training data for E09000012. 222/315\n",
      "train: (3348, 9)   predict: (670, 9)\n",
      "MSE for E09000012: 301.1149253731343\n",
      "Getting the testing and training data for E06000012. 223/315\n",
      "train: (2028, 9)   predict: (670, 9)\n",
      "MSE for E06000012: 1075.4492537313433\n",
      "Getting the testing and training data for E06000033. 224/315\n",
      "train: (1352, 9)   predict: (672, 9)\n",
      "MSE for E06000033: 771.7916666666666\n",
      "Getting the testing and training data for E07000041. 225/315\n",
      "train: (1344, 9)   predict: (672, 9)\n",
      "MSE for E07000041: 639.7797619047619\n",
      "Getting the testing and training data for E07000043. 226/315\n",
      "train: (2006, 9)   predict: (636, 9)\n",
      "MSE for E07000043: 604.9009433962265\n",
      "Getting the testing and training data for E07000112. 227/315\n",
      "train: (2678, 9)   predict: (670, 9)\n",
      "MSE for E07000112: 90.74179104477612\n",
      "Getting the testing and training data for E07000117. 228/315\n",
      "train: (3364, 9)   predict: (672, 9)\n",
      "MSE for E07000117: 118.16220238095238\n",
      "Getting the testing and training data for E07000132. 229/315\n",
      "train: (4042, 9)   predict: (674, 9)\n",
      "MSE for E07000132: 543.299703264095\n",
      "Getting the testing and training data for E07000165. 230/315\n",
      "train: (4710, 9)   predict: (666, 9)\n",
      "MSE for E07000165: 8542.888888888889\n",
      "Getting the testing and training data for E07000222. 231/315\n",
      "train: (2690, 9)   predict: (672, 9)\n",
      "MSE for E07000222: 405.51339285714283\n",
      "Getting the testing and training data for E08000003. 232/315\n",
      "train: (5462, 9)   predict: (670, 9)\n",
      "MSE for E08000003: 7229.565671641791\n",
      "Getting the testing and training data for E06000045. 233/315\n",
      "train: (1344, 9)   predict: (672, 9)\n",
      "MSE for E06000045: 1335.9940476190477\n",
      "Getting the testing and training data for E07000007. 234/315\n",
      "train: (4098, 9)   predict: (670, 9)\n",
      "MSE for E07000007: 1195.744776119403\n",
      "Getting the testing and training data for E07000129. 235/315\n",
      "train: (4046, 9)   predict: (676, 9)\n",
      "MSE for E07000129: 458.8639053254438\n",
      "Getting the testing and training data for E07000151. 236/315\n",
      "train: (4738, 9)   predict: (682, 9)\n",
      "MSE for E07000151: 169.11730205278593\n",
      "Getting the testing and training data for E07000170. 237/315\n",
      "train: (4696, 9)   predict: (674, 9)\n",
      "MSE for E07000170: 186.8026706231454\n",
      "Getting the testing and training data for E07000217. 238/315\n",
      "train: (2694, 9)   predict: (670, 9)\n",
      "MSE for E07000217: 121.72238805970149\n",
      "Getting the testing and training data for E08000006. 239/315\n",
      "train: (4040, 9)   predict: (684, 9)\n",
      "MSE for E08000006: 2003.1769005847952\n",
      "Getting the testing and training data for E08000019. 240/315\n",
      "train: (3374, 9)   predict: (728, 9)\n",
      "MSE for E08000019: 5760.668956043956\n",
      "Getting the testing and training data for E08000033. 241/315\n",
      "train: (4696, 9)   predict: (672, 9)\n",
      "MSE for E08000033: 10005.175595238095\n",
      "Getting the testing and training data for E09000008. 242/315\n",
      "train: (4058, 9)   predict: (682, 9)\n",
      "MSE for E09000008: 3145.9633431085044\n",
      "Getting the testing and training data for E09000022. 243/315\n",
      "train: (3396, 9)   predict: (678, 9)\n",
      "MSE for E09000022: 704.3864306784661\n",
      "Getting the testing and training data for E09000029. 244/315\n",
      "train: (3388, 9)   predict: (682, 9)\n",
      "MSE for E09000029: 328.88709677419354\n",
      "Getting the testing and training data for E06000056. 245/315\n",
      "train: (6042, 9)   predict: (672, 9)\n",
      "MSE for E06000056: 2830.0699404761904\n",
      "Getting the testing and training data for E07000078. 246/315\n",
      "train: (1354, 9)   predict: (682, 9)\n",
      "MSE for E07000078: 317.4134897360704\n",
      "Getting the testing and training data for E07000082. 247/315\n",
      "train: (2712, 9)   predict: (676, 9)\n",
      "MSE for E07000082: 1181.6360946745563\n",
      "Getting the testing and training data for E07000105. 248/315\n",
      "train: (4022, 9)   predict: (672, 9)\n",
      "MSE for E07000105: 359.3482142857143\n",
      "Getting the testing and training data for E07000126. 249/315\n",
      "train: (2720, 9)   predict: (684, 9)\n",
      "MSE for E07000126: 641.0043859649123\n",
      "Getting the testing and training data for E07000138. 250/315\n",
      "train: (1368, 9)   predict: (686, 9)\n",
      "MSE for E07000138: 203.96064139941691\n",
      "Getting the testing and training data for E07000148. 251/315\n",
      "train: (1344, 9)   predict: (672, 9)\n",
      "MSE for E07000148: 178.31994047619048\n",
      "Getting the testing and training data for E07000149. 252/315\n",
      "train: (3358, 9)   predict: (672, 9)\n",
      "MSE for E07000149: 174.88839285714286\n",
      "Getting the testing and training data for E07000177. 253/315\n",
      "train: (4934, 9)   predict: (728, 9)\n",
      "MSE for E07000177: 589.3131868131868\n",
      "Getting the testing and training data for E07000225. 254/315\n",
      "train: (3364, 9)   predict: (670, 9)\n",
      "MSE for E07000225: 148.19850746268656\n",
      "Getting the testing and training data for E07000227. 255/315\n",
      "train: (5400, 9)   predict: (672, 9)\n",
      "MSE for E07000227: 258.25\n",
      "Getting the testing and training data for E08000025. 256/315\n",
      "train: (4708, 9)   predict: (672, 9)\n",
      "MSE for E08000025: 77523.31398809524\n",
      "Getting the testing and training data for E08000028. 257/315\n",
      "train: (2690, 9)   predict: (672, 9)\n",
      "MSE for E08000028: 810.1607142857143\n",
      "Getting the testing and training data for E08000036. 258/315\n",
      "train: (3354, 9)   predict: (672, 9)\n",
      "MSE for E08000036: 954.733630952381\n",
      "Getting the testing and training data for E06000001. 259/315\n",
      "train: (1358, 9)   predict: (682, 9)\n",
      "MSE for E06000001: 1539.0879765395894\n",
      "Getting the testing and training data for E06000010. 260/315\n",
      "train: (682, 9)   predict: (674, 9)\n",
      "MSE for E06000010: 1208.973293768546\n",
      "Getting the testing and training data for E06000017. 261/315\n",
      "train: (3424, 9)   predict: (672, 9)\n",
      "MSE for E06000017: 1219.7098214285713\n",
      "Getting the testing and training data for E07000047. 262/315\n",
      "train: (3370, 9)   predict: (682, 9)\n",
      "MSE for E07000047: 23080.819648093842\n",
      "Getting the testing and training data for E07000066. 263/315\n",
      "train: (3392, 9)   predict: (680, 9)\n",
      "MSE for E07000066: 1148.8073529411765\n",
      "Getting the testing and training data for E07000068. 264/315\n",
      "train: (3380, 9)   predict: (682, 9)\n",
      "MSE for E07000068: 468.02346041055716\n",
      "Getting the testing and training data for E07000091. 265/315\n",
      "train: (2688, 9)   predict: (728, 9)\n",
      "MSE for E07000091: 12694.445054945056\n",
      "Getting the testing and training data for E07000092. 266/315\n",
      "train: (2698, 9)   predict: (674, 9)\n",
      "MSE for E07000092: 160.3887240356083\n",
      "Getting the testing and training data for E07000153. 267/315\n",
      "train: (3440, 9)   predict: (674, 9)\n",
      "MSE for E07000153: 235.17062314540058\n",
      "Getting the testing and training data for E07000164. 268/315\n",
      "train: (6096, 9)   predict: (684, 9)\n",
      "MSE for E07000164: 772.359649122807\n",
      "Getting the testing and training data for E08000010. 269/315\n",
      "train: (4064, 9)   predict: (670, 9)\n",
      "MSE for E08000010: 2320.8358208955224\n",
      "Getting the testing and training data for E09000006. 270/315\n",
      "train: (5390, 9)   predict: (672, 9)\n",
      "MSE for E09000006: 1812.9404761904761\n",
      "Getting the testing and training data for E09000015. 271/315\n",
      "train: (4020, 9)   predict: (672, 9)\n",
      "MSE for E09000015: 2350.470238095238\n",
      "Getting the testing and training data for E06000032. 272/315\n",
      "train: (1350, 9)   predict: (672, 9)\n",
      "MSE for E06000032: 1564.017857142857\n",
      "Getting the testing and training data for E06000044. 273/315\n",
      "train: (2026, 9)   predict: (676, 9)\n",
      "MSE for E06000044: 1183.8047337278106\n",
      "Getting the testing and training data for E07000073. 274/315\n",
      "train: (1348, 9)   predict: (670, 9)\n",
      "MSE for E07000073: 184.37014925373134\n",
      "Getting the testing and training data for E07000173. 275/315\n",
      "train: (2692, 9)   predict: (668, 9)\n",
      "MSE for E07000173: 244.25299401197606\n",
      "Getting the testing and training data for E07000175. 276/315\n",
      "train: (6078, 9)   predict: (670, 9)\n",
      "MSE for E07000175: 174.30447761194029\n",
      "Getting the testing and training data for E07000192. 277/315\n",
      "train: (2702, 9)   predict: (674, 9)\n",
      "MSE for E07000192: 2700.152818991098\n",
      "Getting the testing and training data for E07000195. 278/315\n",
      "train: (3410, 9)   predict: (682, 9)\n",
      "MSE for E07000195: 2406.1099706744867\n",
      "Getting the testing and training data for E07000228. 279/315\n",
      "train: (4056, 9)   predict: (678, 9)\n",
      "MSE for E07000228: 459.6401179941003\n",
      "Getting the testing and training data for E07000242. 280/315\n",
      "train: (4724, 9)   predict: (676, 9)\n",
      "MSE for E07000242: 253.98224852071007\n",
      "Getting the testing and training data for E09000004. 281/315\n",
      "train: (2684, 9)   predict: (672, 9)\n",
      "MSE for E09000004: 530.9136904761905\n",
      "Getting the testing and training data for E09000023. 282/315\n",
      "train: (2018, 9)   predict: (670, 9)\n",
      "MSE for E09000023: 268.1044776119403\n",
      "Getting the testing and training data for E06000006. 283/315\n",
      "train: (3390, 9)   predict: (672, 9)\n",
      "MSE for E06000006: 940.3824404761905\n",
      "Getting the testing and training data for E06000034. 284/315\n",
      "train: (2032, 9)   predict: (674, 9)\n",
      "MSE for E06000034: 401.4213649851632\n",
      "Getting the testing and training data for E07000109. 285/315\n",
      "train: (2676, 9)   predict: (670, 9)\n",
      "MSE for E07000109: 110.04179104477612\n",
      "Getting the testing and training data for E07000115. 286/315\n",
      "train: (3354, 9)   predict: (666, 9)\n",
      "MSE for E07000115: 400.9924924924925\n",
      "Getting the testing and training data for E07000127. 287/315\n",
      "train: (3386, 9)   predict: (682, 9)\n",
      "MSE for E07000127: 1171.2609970674487\n",
      "Getting the testing and training data for E07000134. 288/315\n",
      "train: (4732, 9)   predict: (674, 9)\n",
      "MSE for E07000134: 712.2774480712167\n",
      "Getting the testing and training data for E07000147. 289/315\n",
      "train: (2690, 9)   predict: (672, 9)\n",
      "MSE for E07000147: 267.3482142857143\n",
      "Getting the testing and training data for E07000194. 290/315\n",
      "train: (6070, 9)   predict: (674, 9)\n",
      "MSE for E07000194: 4630.985163204748\n",
      "Getting the testing and training data for E07000208. 291/315\n",
      "train: (2700, 9)   predict: (674, 9)\n",
      "MSE for E07000208: 793.406528189911\n",
      "Getting the testing and training data for E07000226. 292/315\n",
      "train: (3362, 9)   predict: (672, 9)\n",
      "MSE for E07000226: 389.73511904761904\n",
      "Getting the testing and training data for E08000005. 293/315\n",
      "train: (3366, 9)   predict: (670, 9)\n",
      "MSE for E08000005: 1414.0477611940298\n",
      "Getting the testing and training data for E08000008. 294/315\n",
      "train: (2744, 9)   predict: (674, 9)\n",
      "MSE for E08000008: 438.01780415430267\n",
      "Getting the testing and training data for E09000009. 295/315\n",
      "train: (3350, 9)   predict: (668, 9)\n",
      "MSE for E09000009: 550.2814371257485\n",
      "Getting the testing and training data for E06000007. 296/315\n",
      "train: (4734, 9)   predict: (672, 9)\n",
      "MSE for E06000007: 803.1026785714286\n",
      "Getting the testing and training data for E06000018. 297/315\n",
      "train: (2700, 9)   predict: (664, 9)\n",
      "MSE for E06000018: 3582.097891566265\n",
      "Getting the testing and training data for E06000031. 298/315\n",
      "train: (3340, 9)   predict: (670, 9)\n",
      "MSE for E06000031: 2411.310447761194\n",
      "Getting the testing and training data for E06000035. 299/315\n",
      "train: (2680, 9)   predict: (670, 9)\n",
      "MSE for E06000035: 1494.765671641791\n",
      "Getting the testing and training data for E07000009. 300/315\n",
      "train: (3368, 9)   predict: (672, 9)\n",
      "MSE for E07000009: 373.58184523809524\n",
      "Getting the testing and training data for E07000045. 301/315\n",
      "train: (4042, 9)   predict: (672, 9)\n",
      "MSE for E07000045: 240.02380952380952\n",
      "Getting the testing and training data for E07000083. 302/315\n",
      "train: (4734, 9)   predict: (676, 9)\n",
      "MSE for E07000083: 132.44378698224853\n",
      "Getting the testing and training data for E07000128. 303/315\n",
      "train: (3422, 9)   predict: (686, 9)\n",
      "MSE for E07000128: 219.3192419825073\n",
      "Getting the testing and training data for E07000215. 304/315\n",
      "train: (4716, 9)   predict: (672, 9)\n",
      "MSE for E07000215: 164.4092261904762\n",
      "Getting the testing and training data for E07000218. 305/315\n",
      "train: (5382, 9)   predict: (670, 9)\n",
      "MSE for E07000218: 2367.4731343283584\n",
      "Getting the testing and training data for E07000243. 306/315\n",
      "train: (1354, 9)   predict: (684, 9)\n",
      "MSE for E07000243: 432.9590643274854\n",
      "Getting the testing and training data for E08000013. 307/315\n",
      "train: (3374, 9)   predict: (670, 9)\n",
      "MSE for E08000013: 467.7044776119403\n",
      "Getting the testing and training data for E06000037. 308/315\n",
      "train: (4814, 9)   predict: (672, 9)\n",
      "MSE for E06000037: 7372.918154761905\n",
      "Getting the testing and training data for E06000047. 309/315\n",
      "train: (5410, 9)   predict: (672, 9)\n",
      "MSE for E06000047: 9939.10119047619\n",
      "Getting the testing and training data for E07000044. 310/315\n",
      "train: (2702, 9)   predict: (678, 9)\n",
      "MSE for E07000044: 4497.718289085546\n",
      "Getting the testing and training data for E07000071. 311/315\n",
      "train: (2718, 9)   predict: (682, 9)\n",
      "MSE for E07000071: 543.2639296187683\n",
      "Getting the testing and training data for E07000084. 312/315\n",
      "train: (4032, 9)   predict: (670, 9)\n",
      "MSE for E07000084: 346.20597014925374\n",
      "Getting the testing and training data for E07000116. 313/315\n",
      "train: (4016, 9)   predict: (672, 9)\n",
      "MSE for E07000116: 325.7529761904762\n",
      "Getting the testing and training data for E07000176. 314/315\n",
      "train: (5370, 9)   predict: (684, 9)\n",
      "MSE for E07000176: 588.0014619883041\n",
      "Getting the testing and training data for E09000017. 315/315\n",
      "train: (4718, 9)   predict: (668, 9)\n",
      "MSE for E09000017: 1000.1991017964071\n",
      "\n",
      "\n",
      "{'Area': ['E06000003', 'E07000040', 'E07000090', 'E07000214', 'E07000229', 'E08000001', 'E08000009', 'E08000016', 'E08000032', 'E09000003', 'E09000018', 'E09000032', 'E09000033', 'E07000006', 'E07000067', 'E07000094', 'E07000125', 'E07000155', 'E07000169', 'E07000187', 'E07000203', 'E07000234', 'E08000037', 'E09000024', 'E06000038', 'E07000010', 'E07000031', 'E07000079', 'E07000096', 'E07000099', 'E07000145', 'E07000189', 'E07000235', 'E08000015', 'E08000021', 'E06000004', 'E06000021', 'E06000030', 'E07000026', 'E07000032', 'E07000069', 'E07000119', 'E07000140', 'E07000168', 'E07000212', 'E08000011', 'E09000020', 'E09000026', 'E06000005', 'E06000051', 'E07000072', 'E07000074', 'E07000088', 'E07000095', 'E07000154', 'E07000221', 'E07000238', 'E07000239', 'E07000240', 'E09000016', 'E09000019', 'E06000054', 'E07000012', 'E07000034', 'E07000035', 'E07000080', 'E07000110', 'E07000130', 'E07000146', 'E07000171', 'E07000198', 'E08000030', 'E09000007', 'E09000013', 'E06000013', 'E06000025', 'E06000026', 'E06000040', 'E06000059', 'E07000027', 'E07000063', 'E07000077', 'E07000086', 'E07000122', 'E07000200', 'E08000027', 'E08000029', 'E06000019', 'E06000049', 'E07000039', 'E07000076', 'E07000102', 'E07000135', 'E07000167', 'E07000180', 'E08000018', 'E08000026', 'E08000034', 'E09000030', 'E06000008', 'E06000039', 'E07000008', 'E07000030', 'E07000137', 'E07000142', 'E07000199', 'E07000224', 'E07000246', 'E08000014', 'E09000002', 'E09000005', 'E09000011', 'E06000052', 'E07000042', 'E07000085', 'E07000093', 'E07000108', 'E07000111', 'E07000114', 'E07000124', 'E07000193', 'E07000211', 'E07000220', 'E07000236', 'E08000022', 'E08000024', 'E06000009', 'E06000022', 'E06000055', 'E07000033', 'E07000038', 'E07000064', 'E07000123', 'E07000197', 'E07000207', 'E08000012', 'E09000028', 'E09000031', 'E06000043', 'E06000057', 'E07000011', 'E07000089', 'E07000120', 'E07000141', 'E07000178', 'E07000209', 'E09000010', 'E06000002', 'E06000020', 'E07000004', 'E07000036', 'E07000121', 'E07000131', 'E07000219', 'E07000244', 'E07000245', 'E08000004', 'E09000021', 'E09000025', 'E06000011', 'E06000036', 'E06000041', 'E06000042', 'E07000087', 'E07000103', 'E07000136', 'E07000152', 'E07000202', 'E07000213', 'E07000223', 'E06000014', 'E07000028', 'E07000029', 'E07000062', 'E07000065', 'E07000075', 'E07000113', 'E07000156', 'E07000166', 'E07000188', 'E07000210', 'E07000237', 'E08000035', 'E06000023', 'E06000050', 'E07000061', 'E07000070', 'E07000118', 'E07000139', 'E07000179', 'E07000181', 'E07000196', 'E08000007', 'E08000023', 'E08000031', 'E09000014', 'E06000015', 'E07000005', 'E07000046', 'E07000081', 'E07000098', 'E07000143', 'E07000144', 'E07000150', 'E07000172', 'E07000174', 'E08000002', 'E09000027', 'E06000016', 'E06000024', 'E06000027', 'E06000058', 'E07000037', 'E07000106', 'E07000107', 'E07000133', 'E07000163', 'E07000216', 'E07000241', 'E08000017', 'E09000012', 'E06000012', 'E06000033', 'E07000041', 'E07000043', 'E07000112', 'E07000117', 'E07000132', 'E07000165', 'E07000222', 'E08000003', 'E06000045', 'E07000007', 'E07000129', 'E07000151', 'E07000170', 'E07000217', 'E08000006', 'E08000019', 'E08000033', 'E09000008', 'E09000022', 'E09000029', 'E06000056', 'E07000078', 'E07000082', 'E07000105', 'E07000126', 'E07000138', 'E07000148', 'E07000149', 'E07000177', 'E07000225', 'E07000227', 'E08000025', 'E08000028', 'E08000036', 'E06000001', 'E06000010', 'E06000017', 'E07000047', 'E07000066', 'E07000068', 'E07000091', 'E07000092', 'E07000153', 'E07000164', 'E08000010', 'E09000006', 'E09000015', 'E06000032', 'E06000044', 'E07000073', 'E07000173', 'E07000175', 'E07000192', 'E07000195', 'E07000228', 'E07000242', 'E09000004', 'E09000023', 'E06000006', 'E06000034', 'E07000109', 'E07000115', 'E07000127', 'E07000134', 'E07000147', 'E07000194', 'E07000208', 'E07000226', 'E08000005', 'E08000008', 'E09000009', 'E06000007', 'E06000018', 'E06000031', 'E06000035', 'E07000009', 'E07000045', 'E07000083', 'E07000128', 'E07000215', 'E07000218', 'E07000243', 'E08000013', 'E06000037', 'E06000047', 'E07000044', 'E07000071', 'E07000084', 'E07000116', 'E07000176', 'E09000017'], 'MSE': [925.4897959183673, 6669.739583333333, 136.7440828402367, 202.41348973607037, 432.1815476190476, 1377.797619047619, 974.3605341246291, 766.2514880952381, 13164.912202380952, 3184.6029850746268, 1496.431343283582, 1662.0116959064328, 385.87014925373137, 942.8856304985337, 522.3558823529412, 203.60416666666666, 1341.3179104477613, 1439.3782991202347, 4534.577844311377, 390.70386904761904, 74.59850746268657, 197.4985119047619, 1025.0982142857142, 1355.2280701754387, 812.0074404761905, 102.73134328358209, 135.13513513513513, 2643.660766961652, 271.0748502994012, 273.9646017699115, 771.1409495548961, 244.93768545994067, 5333.836309523809, 1734.9212827988338, 1288.1038575667656, 968.265306122449, 2174.6681286549706, 2633.9218289085547, 318.89762611275967, 503.3649851632047, 159.52654867256638, 594.6836734693877, 103.71076923076923, 302.29315476190476, 122.65223880597014, 2756.7625368731565, 374.45359281437123, 1415.4582089552239, 1178.2128279883382, 5688.409090909091, 385.3511904761905, 916.9093567251462, 125.68879056047197, 162.38690476190476, 2810.004385964912, 190.89850746268658, 244.1437125748503, 125.18373493975903, 246.64136904761904, 655.1044776119403, 215.60714285714286, 13881.483630952382, 186.4795321637427, 138.7967359050445, 507.5674486803519, 158.64940828402368, 260.9434523809524, 912.1928783382789, 178.40029761904762, 623.1032934131737, 3561.2587719298244, 2823.9480712166173, 4593.145833333333, 1248.7731343283583, 353.4375, 5403.653846153846, 4195.399705014749, 494.89614243323444, 3496.815476190476, 123.60701754385966, 4149.008771929824, 508.52225519287833, 245.33482142857142, 14845.928358208956, 319.01636904761904, 3486.3318452380954, 1816.479228486647, 1607.1955223880598, 1605.2861356932153, 163.95307917888562, 700.241935483871, 121.24183976261128, 820.2455621301775, 336.9002976190476, 331.6043956043956, 1191.28125, 1919.9806547619048, 2239.1194029850744, 660.755223880597, 1853.7537313432836, 1248.8479532163742, 388.2426900584795, 356.8293413173653, 172.72619047619048, 278.5687134502924, 183.7005988023952, 454.3363095238095, 704.9910447761195, 2217.5219298245615, 909.25, 1269.0611940298506, 312.9717261904762, 20859.793859649122, 354.77245508982037, 196.45684523809524, 408.9717261904762, 219.74477611940299, 189.82388059701492, 150.5907738095238, 139.33970588235294, 454.61127596439167, 726.2089552238806, 682.0192878338279, 121.90210843373494, 758.5431547619048, 1044.0505952380952, 746.204081632653, 1842.3731343283582, 415.9710365853659, 329.52225519287833, 305.0682492581602, 505.0421686746988, 564.704081632653, 2041.0146627565982, 526.5850746268657, 9648.0, 366.25964391691394, 322.0865671641791, 4141.464912280701, 4811.182492581603, 803.3820895522388, 184.29464285714286, 204.55059523809524, 238.0952380952381, 438.0315934065934, 189.62053571428572, 2383.1776119402984, 342.1093294460641, 2179.455489614243, 552.9149253731343, 165.16617210682492, 499.6432748538012, 632.1183431952662, 6033.918397626113, 941.0282738095239, 264.8675595238095, 4432.263392857143, 3394.7227138643066, 803.0451807228916, 4554.7111436950145, 231.82890855457228, 409.33035714285717, 2928.1071428571427, 207.5796460176991, 565.0610119047619, 85.01923076923077, 966.8702064896755, 462.66815476190476, 3280.145209580838, 441.88269794721407, 1529.532738095238, 468.48214285714283, 165.79525222551928, 140.59969325153375, 429.6309523809524, 148.25370919881306, 305.1220238095238, 163.65486725663717, 400.7835820895522, 466.8363095238095, 875.3507462686567, 344.1600609756098, 17252.650297619046, 4622.721153846154, 1607.871720116618, 304.0776119402985, 568.8508771929825, 3695.2719298245615, 137.48976608187135, 443.7541208791209, 139.8901098901099, 329.5327380952381, 2127.0837912087914, 614.3358208955224, 423.70684523809524, 2837.1934523809523, 1965.7390029325513, 208.38541666666666, 25513.672155688622, 352.9120234604106, 6218.858208955224, 203.6577380952381, 203.67708333333334, 224.2479338842975, 204.01632047477744, 268.125, 1293.4956011730205, 5201.273809523809, 3671.434523809524, 1398.320474777448, 537.0149253731344, 4049.8065476190477, 3058.3293768545996, 221.81994047619048, 384.7985074626866, 1024.1815476190477, 18381.636904761905, 190.96279761904762, 198.17507418397625, 661.6220238095239, 301.1149253731343, 1075.4492537313433, 771.7916666666666, 639.7797619047619, 604.9009433962265, 90.74179104477612, 118.16220238095238, 543.299703264095, 8542.888888888889, 405.51339285714283, 7229.565671641791, 1335.9940476190477, 1195.744776119403, 458.8639053254438, 169.11730205278593, 186.8026706231454, 121.72238805970149, 2003.1769005847952, 5760.668956043956, 10005.175595238095, 3145.9633431085044, 704.3864306784661, 328.88709677419354, 2830.0699404761904, 317.4134897360704, 1181.6360946745563, 359.3482142857143, 641.0043859649123, 203.96064139941691, 178.31994047619048, 174.88839285714286, 589.3131868131868, 148.19850746268656, 258.25, 77523.31398809524, 810.1607142857143, 954.733630952381, 1539.0879765395894, 1208.973293768546, 1219.7098214285713, 23080.819648093842, 1148.8073529411765, 468.02346041055716, 12694.445054945056, 160.3887240356083, 235.17062314540058, 772.359649122807, 2320.8358208955224, 1812.9404761904761, 2350.470238095238, 1564.017857142857, 1183.8047337278106, 184.37014925373134, 244.25299401197606, 174.30447761194029, 2700.152818991098, 2406.1099706744867, 459.6401179941003, 253.98224852071007, 530.9136904761905, 268.1044776119403, 940.3824404761905, 401.4213649851632, 110.04179104477612, 400.9924924924925, 1171.2609970674487, 712.2774480712167, 267.3482142857143, 4630.985163204748, 793.406528189911, 389.73511904761904, 1414.0477611940298, 438.01780415430267, 550.2814371257485, 803.1026785714286, 3582.097891566265, 2411.310447761194, 1494.765671641791, 373.58184523809524, 240.02380952380952, 132.44378698224853, 219.3192419825073, 164.4092261904762, 2367.4731343283584, 432.9590643274854, 467.7044776119403, 7372.918154761905, 9939.10119047619, 4497.718289085546, 543.2639296187683, 346.20597014925374, 325.7529761904762, 588.0014619883041, 1000.1991017964071]}\n"
     ]
    }
   ],
   "source": [
    "# the input data file\n",
    "tablePath = \"../data/table.csv\"\n",
    "table = pd.read_csv(tablePath)\n",
    "\n",
    "# remove any nans\n",
    "before = table.shape[0]\n",
    "table = table.dropna()\n",
    "after = table.shape[0]\n",
    "print(f\"{after - before} rows were dropped due to empty values\")\n",
    "\n",
    "# get a list of each unique area code\n",
    "areas = table['areaCode'].unique()\n",
    "\n",
    "# note the columns which are non-numeric. They will require factorising\n",
    "columnsToFactorise = ['areaCode', 'areaName', 'areaType', 'date', 'age']\n",
    "\n",
    "# note the performance metrics\n",
    "metrics = {\n",
    "    'Area':[],\n",
    "    'MSE': []\n",
    "}\n",
    "\n",
    "# get the data\n",
    "i = 0\n",
    "n = len(areas)\n",
    "for area in areas:\n",
    "    i += 1\n",
    "\n",
    "    print(f\"Getting the testing and training data for {area}. {i}/{n}\")\n",
    "    toTrain, toPredict = getTestTrain(area, table, columnsToFactorise)\n",
    "    print(f\"train: {toTrain.shape}   predict: {toPredict.shape}\")\n",
    "\n",
    "    # split up the data for testing and training\n",
    "    trainY = toTrain.loc[:, 'cases']\n",
    "    trainX = toTrain.drop('cases', axis=1)\n",
    "\n",
    "    testY = toPredict.loc[:, 'cases']\n",
    "    testX = toPredict.drop('cases', axis=1)\n",
    "\n",
    "    # removing empty columns might lead to a lack of test or training data.\n",
    "    if trainX.shape[0] == 0 or trainY.shape[0] == 0 or testX.shape[0] == 0 or testY.shape[0] == 0:\n",
    "        print(f\"Missing data. Skipping {area}\")\n",
    "        continue\n",
    "\n",
    "    # set up algorithm(s)\n",
    "    tree = DecisionTreeRegressor() #KeyError: 'squared_error'\n",
    "\n",
    "    # Train algorithm (s)\n",
    "    tree.fit(trainX, trainY)\n",
    "\n",
    "    # Test algorithm (s)\n",
    "    predY = expectedCases = tree.predict(testX)\n",
    "\n",
    "    # output metrics\n",
    "    mse = mean_squared_error(testY, predY)\n",
    "\n",
    "    metrics['Area'].append(area)\n",
    "    metrics['MSE'].append(mse)\n",
    "    print(f\"MSE for {area}: {mse}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(metrics)\n",
    "\n",
    "metrics = pd.DataFrame(metrics)\n",
    "metrics.to_csv('../data/performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c29eaa",
   "metadata": {},
   "source": [
    "We will now load the results table back in and examine the performance of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4a9d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Area</th>\n",
       "      <th>fdecision_MSE</th>\n",
       "      <th>fdecision_r2</th>\n",
       "      <th>fknn_MSE</th>\n",
       "      <th>fknn_r2</th>\n",
       "      <th>flinear_MSE</th>\n",
       "      <th>flinear_r2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E06000003</td>\n",
       "      <td>836.590379</td>\n",
       "      <td>0.555964</td>\n",
       "      <td>1298.869621</td>\n",
       "      <td>0.310601</td>\n",
       "      <td>1417.546911</td>\n",
       "      <td>0.247611</td>\n",
       "      <td>1184.335637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E07000040</td>\n",
       "      <td>5934.647321</td>\n",
       "      <td>-4.723592</td>\n",
       "      <td>2389.419940</td>\n",
       "      <td>-1.304444</td>\n",
       "      <td>740.639088</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>3021.568783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E07000090</td>\n",
       "      <td>136.337278</td>\n",
       "      <td>0.833524</td>\n",
       "      <td>365.066509</td>\n",
       "      <td>0.554233</td>\n",
       "      <td>517.854261</td>\n",
       "      <td>0.367671</td>\n",
       "      <td>339.752683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E07000214</td>\n",
       "      <td>177.818182</td>\n",
       "      <td>0.689283</td>\n",
       "      <td>315.430792</td>\n",
       "      <td>0.448820</td>\n",
       "      <td>382.630961</td>\n",
       "      <td>0.331396</td>\n",
       "      <td>291.959978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E07000229</td>\n",
       "      <td>434.450893</td>\n",
       "      <td>0.267936</td>\n",
       "      <td>406.557143</td>\n",
       "      <td>0.314938</td>\n",
       "      <td>473.349328</td>\n",
       "      <td>0.202391</td>\n",
       "      <td>438.119121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Area  fdecision_MSE  fdecision_r2     fknn_MSE   fknn_r2  \\\n",
       "0           0  E06000003     836.590379      0.555964  1298.869621  0.310601   \n",
       "1           1  E07000040    5934.647321     -4.723592  2389.419940 -1.304444   \n",
       "2           2  E07000090     136.337278      0.833524   365.066509  0.554233   \n",
       "3           3  E07000214     177.818182      0.689283   315.430792  0.448820   \n",
       "4           4  E07000229     434.450893      0.267936   406.557143  0.314938   \n",
       "\n",
       "   flinear_MSE  flinear_r2          MSE  \n",
       "0  1417.546911    0.247611  1184.335637  \n",
       "1   740.639088    0.285700  3021.568783  \n",
       "2   517.854261    0.367671   339.752683  \n",
       "3   382.630961    0.331396   291.959978  \n",
       "4   473.349328    0.202391   438.119121  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the results table \n",
    "results = pd.read_csv('../data/final_performance.csv')\n",
    "results[\"MSE\"] = results[['fdecision_MSE', 'fknn_MSE', 'flinear_MSE']].mean(axis=1)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98257dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start with a simple plot\n",
    "plt.bar(x=results.Area, height=results.MSE)\n",
    "plt.ylim(top=20000)\n",
    "plt.savefig(\"./images/errorsByTrust.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c356686",
   "metadata": {},
   "source": [
    "Quantify the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e73f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(results.MSE, bins=15)\n",
    "plt.savefig(\"./images/errorsHist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9c2f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum error: 71546.25572662562\n",
      "Minimum error: 126.57596815125919\n",
      "Average error: 1967.4952249982566\n",
      "Variance of error: 22587548.02756681\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum error: {max(results.MSE)}\")\n",
    "print(f\"Minimum error: {min(results.MSE)}\")\n",
    "print(f\"Average error: {np.mean(results.MSE)}\")\n",
    "print(f\"Variance of error: {np.var(results.MSE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06e4163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pruned = results[results.MSE < 4000]\n",
    "plt.hist(pruned.MSE, bins=30)\n",
    "plt.savefig(\"./images/zoomedHist.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
